# -*- coding: utf-8 -*-
"""SC_project_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15VQ4gQdFzZlZH748_7lEVYo6njQx5Q86
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# from google.colab import drive
# drive.mount('/content/drive')

# df = pd.read_csv('/content/drive/MyDrive/balance_data_folder/balanced_policy.csv')
df=pd.read_csv("balanced_policy.csv")
df.head()

df.describe()

df.call_duration.describe()

df.conversion_status.value_counts()

df.occupation.value_counts()

df["Age Group"] = pd.cut(df["age"], bins=5, labels=["18-30", "31-55", "55-70", "70-90", "90-More"])

pd.crosstab(index=df["occupation"], columns = df["conversion_status"])

df.groupby('occupation')['Age Group'].value_counts()

pd.crosstab(index=df["occupation"], columns = df["Age Group"])

plt.figure(figsize=(10, 6))
sns.countplot(x='Age Group', hue='marital_status', data=df, palette='coolwarm')
plt.title('Distribution of Marital Statuses Across Age Groups')
plt.xlabel('Age Group')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.legend(title='Marital Status')
plt.tight_layout()
plt.show()

#sns.barplot(x=occupation.index, y=Age Group.values, hue=occupation.index)
plt.figure(figsize=(13,6))
sns.countplot(df,x='occupation', hue='Age Group')
plt.xticks(rotation=90)
plt.show()

df = df.drop(columns='Age Group')

pd.crosstab(index=df["education_level"], columns = df["conversion_status"])

sns.countplot(df, x='conversion_status',hue='education_level' )

pd.crosstab(index=df['marital_status'], columns=df['communication_channel'])

sns.countplot(df, x='marital_status', hue='communication_channel')

np.round(pd.pivot_table(df,index='call_month', columns='call_day', values='call_duration', fill_value=0)).T

pd.crosstab( index=df['call_month'], columns=df['call_day'], values=df['call_duration'], aggfunc='sum').T

pd.crosstab(index=df['conversion_status'], columns=df['previous_campaign_outcome'])

sns.countplot(df,x='conversion_status', hue='previous_campaign_outcome')

df.occupation.value_counts() ## pd.get_dummies

occ = pd.get_dummies(df,columns=['occupation'],dtype='int', drop_first=True)

df = pd.concat([df['occupation'], occ], axis=1 )

df.drop('occupation', axis=1, inplace=True)

"""# Label Encoding"""

from sklearn.preprocessing import LabelEncoder

model = LabelEncoder()

model.fit_transform(df['call_month'])

df['call_month']= model.fit_transform(df['call_month'])
df['call_month'].unique()

df.previous_campaign_outcome.value_counts() #label

model.fit_transform(df['previous_campaign_outcome'])

df['previous_campaign_outcome']

df['previous_campaign_outcome'] = model.fit_transform(df['previous_campaign_outcome'])

X = df.drop('conversion_status', axis=1)
y = df['conversion_status']

"""# OneHotEncoding"""

df=pd.read_csv("/content/balanced_policy.csv")
df

df['conversion_status'].value_counts()

df['conversion_status'].value_counts()

"""# Train Test splite"""

from sklearn.model_selection import train_test_split

X_train , X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=98)

X_train.shape

X_test.shape

"""# Decision Tree"""

import pandas as pd
import numpy as np

# data visualization library
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

sns.set(context='notebook', style='darkgrid', palette='colorblind', font='sans-serif', font_scale=1, rc=None)
matplotlib.rcParams['figure.figsize'] =[8,8]
matplotlib.rcParams.update({'font.size': 15})
matplotlib.rcParams['font.family'] = 'sans-serif'
df=pd.read_csv("/content/drive/MyDrive/balance_data_folder/balanced_policy.csv")
df

df.isnull().sum().sum()

df['previous_campaign_outcome'].unique()

df.info()

df.shape

sns.histplot(df['previous_campaign_outcome'])

X = df.drop(['previous_campaign_outcome'],axis=1)
y = df['previous_campaign_outcome']

X = pd.get_dummies(X)

"""# Encoding"""

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
y = encoder.fit_transform(y)
print(y)

from sklearn.tree import DecisionTreeClassifier
from sklearn import tree

from sklearn.metrics import accuracy_score

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Assume X_train, X_test, y_train, y_test are your training and testing data
# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Assume 'X_train' and 'X_test' are DataFrames with categorical variables
# Perform one-hot encoding on categorical variables
X_train_encoded = pd.get_dummies(X_train)
X_test_encoded = pd.get_dummies(X_test)

# Instantiate the DecisionTreeClassifier with the desired parameters
clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)

# Fit the model
clf_gini.fit(X_train_encoded, y_train)

# Make predictions on the testing data
y_pred = clf_gini.predict(X_test_encoded)

# Compute accuracy
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy)

plt.figure(figsize=(12,8))

tree.plot_tree(clf_gini.fit(X_train, y_train))

#Predict the values
y_pred_gini = clf_gini.predict(X_test)

#Predict the value using X train for accuracy comparision
y_pred_train_gini = clf_gini.predict(X_train)

y_pred_train_gini

#Determine the accuracy score
print('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_gini)))
#Accuracy Score for training set
accuracy_Decision_tree=accuracy_score(y_test, y_pred_gini)

print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_gini)))

from sklearn.metrics import confusion_matrix

# Assuming y_test and y_pred_gini are already defined
cm = confusion_matrix(y_test, y_pred_gini)

print('Confusion matrix\n\n', cm)

f,ax = plt.subplots(figsize=(10, 10))
sns.heatmap(cm, annot=True, linewidths=0.5,linecolor="red", fmt= '.0f',ax=ax)
plt.show()
plt.savefig('ConfusionMatrix.png')

"""# Random Forest and Decsion Tree Accuracy"""

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score, r2_score, recall_score, accuracy_score

# Assuming X contains features and y contains the target variable

# Step 2: Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 3: Train Decision Tree and Random Forest models
decision_tree_classifier = DecisionTreeClassifier()
random_forest_classifier = RandomForestClassifier()

decision_tree_classifier.fit(X_train, y_train)
random_forest_classifier.fit(X_train, y_train)

# Step 4: Make predictions
decision_tree_predictions = decision_tree_classifier.predict(X_test)
random_forest_predictions = random_forest_classifier.predict(X_test)

# Step 5: Calculate metrics
decision_tree_f1 = f1_score(y_test, decision_tree_predictions, average='weighted')
random_forest_f1 = f1_score(y_test, random_forest_predictions, average='weighted')

decision_tree_r2 = r2_score(y_test, decision_tree_predictions)
random_forest_r2 = r2_score(y_test, random_forest_predictions)

decision_tree_recall = recall_score(y_test, decision_tree_predictions, average='weighted')
random_forest_recall = recall_score(y_test, random_forest_predictions, average='weighted')

decision_tree_accuracy = accuracy_score(y_test, decision_tree_predictions)
random_forest_accuracy = accuracy_score(y_test, random_forest_predictions)

# Print the results
print("Decision Tree Metrics:")
print("F1 Score:", decision_tree_f1)
print("R2 Score:", decision_tree_r2)
print("Recall:", decision_tree_recall)
print("Accuracy:", decision_tree_accuracy)

print("\nRandom Forest Metrics:")
print("F1 Score:", random_forest_f1)
print("R2 Score:", random_forest_r2)
print("Recall:", random_forest_recall)
print("Accuracy:", random_forest_accuracy)

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Assuming X_train, X_test, y_train, y_test are already defined
svm_model = SVC(kernel='rbf').fit(X_train, y_train)
y_pred = svm_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

svc = SVC(kernel='rbf')
svc.fit(X_train,y_train)

import pickle
pickle.dump(svc,open('policy.pkl','wb'))